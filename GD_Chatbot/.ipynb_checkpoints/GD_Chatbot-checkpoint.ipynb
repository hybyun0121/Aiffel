{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"Chatbot_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/project/GoingDeeper/GD_Chatbot/Chatbot_data/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path+\"ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = list(df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡!',\n",
       " '1지망 학교 떨어졌어',\n",
       " '3박4일 놀러가고 싶다',\n",
       " '3박4일 정도 놀러가고 싶다',\n",
       " 'PPL 심하네',\n",
       " 'SD카드 망가졌어',\n",
       " 'SD카드 안돼',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루가 또 가네요.',\n",
       " '위로해 드립니다.',\n",
       " '여행은 언제나 좋죠.',\n",
       " '여행은 언제나 좋죠.',\n",
       " '눈살이 찌푸려지죠.',\n",
       " '다시 새로 사는 게 마음 편해요.',\n",
       " '다시 새로 사는 게 마음 편해요.',\n",
       " '잘 모르고 있을 수도 있어요.',\n",
       " '시간을 정하고 해보세요.',\n",
       " '시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9?.!,¿¡ ]\", \"\", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 토큰화\n",
    "애매했던 부분임 데이터 정제를 여기서 하란건지  \n",
    "위에서 하고 아래에서 토큰화만 하란건지 잘 모르겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(que, ans):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q, a in tqdm(zip(que, ans)):\n",
    "        q = preprocess_sentence(q)\n",
    "        a = preprocess_sentence(a)\n",
    "\n",
    "        questions.append(q)\n",
    "        answers.append(a)\n",
    "    \n",
    "    df = pd.DataFrame({\"Q_c\":questions, \"A_c\":answers})\n",
    "    df = df.drop_duplicates(subset=\"Q_c\")\n",
    "    df = df.drop_duplicates(subset=\"A_c\")\n",
    "    \n",
    "    questions=list(df.iloc[:,0])\n",
    "    answers=list(df.iloc[:,1])\n",
    "    \n",
    "    mecab = Mecab()\n",
    "#     questions = [str(tmp)[2:-2] for tmp in list(map(mecab.morphs, questions))]\n",
    "#     answers = [str(tmp)[2:-2] for tmp in list(map(mecab.morphs, answers))]\n",
    "    que_corpus = [tmp for tmp in list(map(mecab.morphs, questions))]\n",
    "    ans_corpus = [tmp for tmp in list(map(mecab.morphs, answers))]\n",
    "    \n",
    "    return que_corpus, ans_corpus\n",
    "#     return questions, answers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11823it [00:00, 156797.53it/s]\n"
     ]
    }
   ],
   "source": [
    "que_tokens, ans_tokens = build_corpus(q_list, a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7731\n"
     ]
    }
   ],
   "source": [
    "assert len(que_tokens) == len(ans_tokens)\n",
    "print(len(que_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', 'ㅠㅠ'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['하루', '가', '또', '가', '네요', '.'],\n",
       " ['위로', '해', '드립니다', '.'],\n",
       " ['여행', '은', '언제나', '좋', '죠', '.'],\n",
       " ['눈살', '이', '찌푸려', '지', '죠', '.'],\n",
       " ['다시', '새로', '사', '는', '게', '마음', '편해요', '.'],\n",
       " ['잘', '모르', '고', '있', '을', '수', '도', '있', '어요', '.'],\n",
       " ['시간', '을', '정하', '고', '해', '보', '세요', '.'],\n",
       " ['자랑', '하', '는', '자리', '니까요', '.'],\n",
       " ['그', '사람', '도', '그럴', '거', '예요', '.'],\n",
       " ['혼자', '를', '즐기', '세요', '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 질문 문장 길이 :  32\n",
      "최소 질문 문장 길이 :  1\n",
      "평균 질문 문장 길이 :  7.48260250937783\n"
     ]
    }
   ],
   "source": [
    "# 문장 길이 분석하기\n",
    "print(\"최대 질문 문장 길이 : \", max(len(x) for x in que_tokens))\n",
    "print(\"최소 질문 문장 길이 : \", min(len(x) for x in que_tokens))\n",
    "print(\"평균 질문 문장 길이 : \", sum(map(len, que_tokens))/len(que_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 대답 문장 길이 :  40\n",
      "최소 질문 문장 길이 :  1\n",
      "평균 대답 문장 길이 :  8.678696158323632\n"
     ]
    }
   ],
   "source": [
    "print(\"최대 대답 문장 길이 : \", max(len(x) for x in ans_tokens))\n",
    "print(\"최소 질문 문장 길이 : \", min(len(x) for x in ans_tokens))\n",
    "print(\"평균 대답 문장 길이 : \", sum(map(len, ans_tokens))/len(ans_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 궁금한거\n",
    "부끄러운 질문 : 적당히 문장을 자르는 기준이 있을까요??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    idx = []\n",
    "    for i,s in enumerate(nested_list):\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "        else:\n",
    "            idx.append(i)\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 20 이하인 샘플의 비율: 99.49553744664338\n"
     ]
    }
   ],
   "source": [
    "idx_over_maxlen_q = below_threshold_len(20, que_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 20 이하인 샘플의 비율: 99.01694476781788\n"
     ]
    }
   ],
   "source": [
    "idx_over_maxlen_a = below_threshold_len(20, ans_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_idx = list(set(idx_over_maxlen_a + idx_over_maxlen_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_idx(del_list, que, ans):\n",
    "    new_que, new_ans = [], []\n",
    "    for i, (q,a) in enumerate(zip(que,ans)):\n",
    "        if i not in del_list:\n",
    "            new_que.append(q)\n",
    "            new_ans.append(a)\n",
    "    return new_que, new_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_tokens, ans_tokens = remove_idx(del_idx, que_tokens, ans_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7616\n"
     ]
    }
   ],
   "source": [
    "assert len(que_tokens) == len(ans_tokens)\n",
    "print(len(que_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '시', '땡', '!'],\n",
       " ['1', '지망', '학교', '떨어졌', '어'],\n",
       " ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'],\n",
       " ['ppl', '심하', '네'],\n",
       " ['sd', '카드', '망가졌', '어'],\n",
       " ['sns', '맞', '팔', '왜', '안', '하', '지', 'ㅠㅠ'],\n",
       " ['sns', '시간', '낭비', '인', '거', '아', '는데', '매일', '하', '는', '중'],\n",
       " ['sns', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여'],\n",
       " ['가끔', '궁금', '해'],\n",
       " ['가끔', '은', '혼자', '인', '게', '좋', '다']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "ko_vec = gensim.models.Word2Vec.load('ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(corpus, word2vec):\n",
    "    import random\n",
    "\n",
    "    res = \"\"\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(corpus)\n",
    "        _to = word2vec.wv.most_similar(_from)[0][0]\n",
    "\n",
    "    except:   # 단어장에 없는 단어\n",
    "        return None\n",
    "\n",
    "    for cor in corpus:\n",
    "        if cor is _from: res += _to + \" \"\n",
    "        else: res += cor + \" \"\n",
    "\n",
    "    return res.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7616it [00:08, 867.72it/s]\n",
      "7616it [00:08, 884.32it/s]\n",
      "7616it [00:08, 879.79it/s]\n",
      "7616it [00:08, 864.67it/s]\n"
     ]
    }
   ],
   "source": [
    "aug_que_tokens, aug_ans_tokens = [], []\n",
    "for _ in range(4):\n",
    "    for i, (q,a) in tqdm(enumerate(zip(que_tokens, ans_tokens))):\n",
    "        aug_que_tokens.append(lexical_sub(q, ko_vec))\n",
    "        aug_ans_tokens.append(lexical_sub(a, ko_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    4362\n",
       "A    3474\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Q\":aug_que_tokens,\"A\":aug_ans_tokens})\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_tokens = list(df.iloc[:,0])\n",
    "ans_tokens = list(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23186\n"
     ]
    }
   ],
   "source": [
    "assert len(que_tokens) == len(ans_tokens)\n",
    "print(len(ans_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23186/23186 [00:00<00:00, 232586.66it/s]\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN = [\"<start>\"]\n",
    "END_TOKEN = [\"<end>\"]\n",
    "\n",
    "for i in tqdm(range(len(que_tokens))):\n",
    "    que_tokens[i] = START_TOKEN + que_tokens[i] + END_TOKEN\n",
    "    ans_tokens[i] = START_TOKEN + ans_tokens[i] + END_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46372"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens = que_tokens + ans_tokens\n",
    "len(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.concatenate(total_tokens).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(words)\n",
    "vocab = ['<pad>', '<unk>'] + [key for key, _ in counter.items()]\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7539"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<unk>' for index in encoded_sentence)  #[1:]를 통해 <BOS>를 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = vectorize(que_tokens, word_to_index)\n",
    "dec_train = vectorize(ans_tokens, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = pad_sequences(enc_train, value=word_to_index[\"<pad>\"], padding='post', maxlen=22)\n",
    "\n",
    "dec_train = pad_sequences(dec_train, value=word_to_index[\"<pad>\"], padding='post', maxlen=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘 됐나 함 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,  447,   19,  935,   19, 1460,   69,    7,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> 12 시가 땡 ! <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_decoded_sentence(enc_train[0], index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> 하루 가 각기 가 네요 . <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_decoded_sentence(dec_train[0], index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_train, dec_train, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *\n",
    "from train_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(n_layers=1,\n",
    "                          d_model=368,\n",
    "                          n_heads=8,\n",
    "                          d_ff=1024,\n",
    "                          src_vocab_size=10000,\n",
    "                          tgt_vocab_size=10000,\n",
    "                          pos_len=200,\n",
    "                          dropout=0.2,\n",
    "                          shared_fc=True,\n",
    "                          shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model,warmup_steps=1000)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 359/359 [00:14<00:00, 25.08it/s, Loss 4.8527]\n",
      "Epoch  2: 100%|██████████| 359/359 [00:11<00:00, 31.87it/s, Loss 3.0121]\n",
      "Epoch  3: 100%|██████████| 359/359 [00:11<00:00, 32.01it/s, Loss 1.9574]\n",
      "Epoch  4: 100%|██████████| 359/359 [00:11<00:00, 31.90it/s, Loss 1.2618]\n",
      "Epoch  5: 100%|██████████| 359/359 [00:11<00:00, 31.87it/s, Loss 0.8478]\n",
      "Epoch  6: 100%|██████████| 359/359 [00:11<00:00, 31.87it/s, Loss 0.6455]\n",
      "Epoch  7: 100%|██████████| 359/359 [00:11<00:00, 31.79it/s, Loss 0.5243]\n",
      "Epoch  8: 100%|██████████| 359/359 [00:11<00:00, 31.82it/s, Loss 0.4545]\n",
      "Epoch  9: 100%|██████████| 359/359 [00:11<00:00, 31.97it/s, Loss 0.3970]\n",
      "Epoch 10: 100%|██████████| 359/359 [00:11<00:00, 31.80it/s, Loss 0.3567]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                         candidate,\n",
    "                         weights=weights,\n",
    "                         smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "def evaluate(sentence, model):\n",
    "    pieces = sentence.split()\n",
    "    tokens = get_encoded_sentence(pieces, word_to_index)\n",
    "\n",
    "    _input = np.array(tokens).reshape((1,-1))\n",
    "\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([word_to_index[\"<start>\"]], 0)\n",
    "    \n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "        \n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "    \n",
    "\n",
    "        if word_to_index[\"<end>\"] == predicted_id:\n",
    "            result = get_decoded_sentence(ids, index_to_word)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = get_decoded_sentence(ids, index_to_word)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "def translate(sentence, model):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model)\n",
    "\n",
    "    return result\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.split()\n",
    "    cleaned_sen = \"\"\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        if (sentence[i] != \"<start>\") and (sentence[i] not in ['<end>', '<pad>']):\n",
    "            cleaned_sen += sentence[i] + \" \"\n",
    "        elif sentence[i] in ['<end>', '<pad>']:\n",
    "            return cleaned_sen\n",
    "    return cleaned_sen\n",
    "    \n",
    "def eval_bleu(src_corpus, tgt_corpus, verbose=True):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(tgt_corpus)\n",
    "\n",
    "    for idx in range(sample_size):\n",
    "        src_tokens = src_corpus[idx]\n",
    "        tgt_tokens = tgt_corpus[idx]\n",
    "\n",
    "        src_sentence = get_decoded_sentence(src_tokens, index_to_word)\n",
    "        tgt_sentence = get_decoded_sentence(tgt_tokens, index_to_word)\n",
    "        candidate = translate(src_sentence, transformer)\n",
    "\n",
    "        score = sentence_bleu(src_sentence, candidate,\n",
    "                              smoothing_function=SmoothingFunction().method1)\n",
    "        total_score += score\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Question Sentence: \", clean_sentence(src_sentence))\n",
    "            print(\"Model Prediction: \", clean_sentence(candidate))\n",
    "            print(\"Real: \", clean_sentence(tgt_sentence))\n",
    "            print(\"Score: %lf\\n\" % score)\n",
    "\n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Total Score:\", total_score / sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Sentence:  4 년 를 엊그제 마무리 했 습니다 \n",
      "Model Prediction:  좋 은 기억 들 그러 었 길 바랄게요 . \n",
      "Real:  좋 은데 마무리 가 되 었 길 바랍니다 . \n",
      "Score: 0.010331\n",
      "\n",
      "Question Sentence:  허전 한 게 좀 이렇 다 \n",
      "Model Prediction:  채워질 거 예요 는데 \n",
      "Real:  채워질 것 예요 . \n",
      "Score: 0.018850\n",
      "\n",
      "Question Sentence:  첫 사랑 느껴지 \n",
      "Model Prediction:  소중 했 던 추억 그러 라고 생각 해 보 세요 . \n",
      "Real:  소중 했 던 추억 이 라고 생각 해 보 ㅂ시오 . \n",
      "Score: 0.006980\n",
      "\n",
      "Question Sentence:  일 일 만보 걷 적기 \n",
      "Model Prediction:  좋 은 건강 습관 그러 네요 . \n",
      "Real:  좋 은 건강 습관 그러 네요 . \n",
      "Score: 0.011503\n",
      "\n",
      "Question Sentence:  남 사친 인데 요즘 관심 가 는데 \n",
      "Model Prediction:  친구 랑 썸 의 중간 인 거 같 아요 는데 \n",
      "Real:  친구 랑 썸 의 중간 인 거 똑같 아요 . \n",
      "Score: 0.012962\n",
      "\n",
      "Question Sentence:  선글라스 말 고 렌즈 껴야 겠어 \n",
      "Model Prediction:  그런 월과 은 되풀이 에 버리 세요 . \n",
      "Real:  변신 은 유죄 ! \n",
      "Score: 0.009134\n",
      "\n",
      "Question Sentence:  붙잡 기에 싶 어 \n",
      "Model Prediction:  아직 사랑 하 고 있 나 봅니다 는데 \n",
      "Real:  그대로 돌아오 지 는 않 을 것 란 걸 인정 하 세요 . \n",
      "Score: 0.009630\n",
      "\n",
      "Question Sentence:  가끔 짝사랑 시키 는 여자 애 랑 데이트 하 는 상상 을 해 . \n",
      "Model Prediction:  상상 은 보하이 상관 없 어요 . \n",
      "Real:  상상 은 보하이 상관 없 어요 . \n",
      "Score: 0.016153\n",
      "\n",
      "Question Sentence:  매번 글 쓸 때 마다 사안 설명 하 라고 해 \n",
      "Model Prediction:  대화 를 많이 나누 는 게 괜찮 으니까요 . \n",
      "Real:  대화 를 자주 나누 는 게 좋 으니까요 . \n",
      "Score: 0.007913\n",
      "\n",
      "Question Sentence:  갑자기 일어난 월과 이 라 어 이 없 어 \n",
      "Model Prediction:  황당 하 군요 . \n",
      "Real:  황당 하 네요 는데 \n",
      "Score: 0.023980\n",
      "\n",
      "Num of Sample: 10\n",
      "Total Score: 0.012743828467321564\n"
     ]
    }
   ],
   "source": [
    "eval_bleu(enc_val[:10], dec_val[:10], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고백 해의 지 는 단계 인가 봐요 .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"내이 날씨는 어때?\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고백 을 해 살펴보 세요 .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"너가 이러면 기분이 안좋아\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'드세요 는데 는데 는데'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"말이되는 소리를 좀 해줘\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정말 나쁜 생각 하 지 말 아요 는데'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"이거 원래 잘 안되나요?\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고백 해의 지 는 단계 네요 .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"속상하다\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서로 를 알 면서 못했 군요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"몇 일을 열심히 했는데 이 모양이니?\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'맞 는 것 을 때 가 네요 는데'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"그러게 나는 널 잘 안다고 생각했는데...\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'고백 해의 주 세요 .'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"여사친인데 요즘 관심법이야\", transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
