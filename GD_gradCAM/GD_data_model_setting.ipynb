{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from data_load import DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoad()\n",
    "(ds_train, ds_test), ds_info = dl.load_tfds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
       "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=196),\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet을 base model로하는 CAM을 뽑을 수 있는 모델을 만들어 보자.\n",
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "base_model = keras.applications.resnet.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224,224,3),\n",
    "    pooling='avg'\n",
    ")\n",
    "x = base_model.output\n",
    "preds = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "cam_model = keras.Model(inputs=base_model.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_norm = dl.apply_normalize_on_dataset(ds_train)\n",
    "ds_test_norm = dl.apply_normalize_on_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)\n",
    "cam_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.join(os.getenv(\"HOME\"), \"project/Going_deeper/GD_gradCAM/best_checkpoint.h5\")\n",
    "getbestmodel = keras.callbacks.ModelCheckpoint(file_path, verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 4.1418 - accuracy: 0.1729\n",
      "Epoch 00001: val_loss improved from inf to 5.43121, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 91s 179ms/step - loss: 4.1418 - accuracy: 0.1729 - val_loss: 5.4312 - val_accuracy: 0.0069\n",
      "Epoch 2/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 1.6170 - accuracy: 0.6548\n",
      "Epoch 00002: val_loss improved from 5.43121 to 1.86947, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 80s 158ms/step - loss: 1.6170 - accuracy: 0.6548 - val_loss: 1.8695 - val_accuracy: 0.5108\n",
      "Epoch 3/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.9110\n",
      "Epoch 00003: val_loss improved from 1.86947 to 1.27520, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.5163 - accuracy: 0.9110 - val_loss: 1.2752 - val_accuracy: 0.6693\n",
      "Epoch 4/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9860\n",
      "Epoch 00004: val_loss improved from 1.27520 to 1.14590, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.1542 - accuracy: 0.9860 - val_loss: 1.1459 - val_accuracy: 0.6986\n",
      "Epoch 5/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9973\n",
      "Epoch 00005: val_loss improved from 1.14590 to 1.12239, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 160ms/step - loss: 0.0622 - accuracy: 0.9973 - val_loss: 1.1224 - val_accuracy: 0.7063\n",
      "Epoch 6/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9988\n",
      "Epoch 00006: val_loss improved from 1.12239 to 1.07911, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 82s 162ms/step - loss: 0.0386 - accuracy: 0.9988 - val_loss: 1.0791 - val_accuracy: 0.7099\n",
      "Epoch 7/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9991\n",
      "Epoch 00007: val_loss improved from 1.07911 to 1.04462, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 160ms/step - loss: 0.0329 - accuracy: 0.9991 - val_loss: 1.0446 - val_accuracy: 0.7183\n",
      "Epoch 8/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9984\n",
      "Epoch 00008: val_loss did not improve from 1.04462\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0211 - accuracy: 0.9984 - val_loss: 1.0548 - val_accuracy: 0.7171\n",
      "Epoch 9/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9994\n",
      "Epoch 00009: val_loss did not improve from 1.04462\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0161 - accuracy: 0.9994 - val_loss: 1.0480 - val_accuracy: 0.7221\n",
      "Epoch 10/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9999\n",
      "Epoch 00010: val_loss improved from 1.04462 to 1.04154, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 160ms/step - loss: 0.0135 - accuracy: 0.9999 - val_loss: 1.0415 - val_accuracy: 0.7229\n",
      "Epoch 11/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9994\n",
      "Epoch 00011: val_loss did not improve from 1.04154\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0147 - accuracy: 0.9994 - val_loss: 1.0478 - val_accuracy: 0.7242\n",
      "Epoch 12/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9990\n",
      "Epoch 00012: val_loss improved from 1.04154 to 1.02874, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 82s 160ms/step - loss: 0.0148 - accuracy: 0.9990 - val_loss: 1.0287 - val_accuracy: 0.7308\n",
      "Epoch 13/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9990\n",
      "Epoch 00013: val_loss did not improve from 1.02874\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0130 - accuracy: 0.9990 - val_loss: 1.0366 - val_accuracy: 0.7245\n",
      "Epoch 14/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9989\n",
      "Epoch 00014: val_loss did not improve from 1.02874\n",
      "509/509 [==============================] - 81s 160ms/step - loss: 0.0132 - accuracy: 0.9989 - val_loss: 1.0474 - val_accuracy: 0.7260\n",
      "Epoch 15/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9995\n",
      "Epoch 00015: val_loss did not improve from 1.02874\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0099 - accuracy: 0.9995 - val_loss: 1.0395 - val_accuracy: 0.7283\n",
      "Epoch 16/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9999\n",
      "Epoch 00016: val_loss improved from 1.02874 to 1.02783, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 81s 160ms/step - loss: 0.0076 - accuracy: 0.9999 - val_loss: 1.0278 - val_accuracy: 0.7266\n",
      "Epoch 17/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9994\n",
      "Epoch 00017: val_loss did not improve from 1.02783\n",
      "509/509 [==============================] - 81s 159ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 1.0388 - val_accuracy: 0.7295\n",
      "Epoch 18/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9998\n",
      "Epoch 00018: val_loss did not improve from 1.02783\n",
      "509/509 [==============================] - 83s 164ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 1.0329 - val_accuracy: 0.7295\n",
      "Epoch 19/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9998\n",
      "Epoch 00019: val_loss did not improve from 1.02783\n",
      "509/509 [==============================] - 82s 161ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 1.0317 - val_accuracy: 0.7308\n",
      "Epoch 20/20\n",
      "509/509 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9995\n",
      "Epoch 00020: val_loss improved from 1.02783 to 1.02119, saving model to /home/aiffel0042/project/Going_deeper/GD_gradCAM/best_checkpoint.h5\n",
      "509/509 [==============================] - 82s 161ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 1.0212 - val_accuracy: 0.7331\n"
     ]
    }
   ],
   "source": [
    "history_cam_model = cam_model.fit(\n",
    "    ds_train_norm, #normalized 학습데이터 (x, y) 둘 다 가지고 있음\n",
    "    steps_per_epoch = int(ds_info.splits[\"train\"].num_examples/16), #batch size = 16\n",
    "    validation_steps=int(ds_info.splits[\"test\"].num_examples/16), #test의 16개를 Validation\n",
    "    epochs=20,\n",
    "    callbacks=[getbestmodel],\n",
    "    validation_data=ds_test_norm, #validation dataset\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save하기\n",
    "cam_model_path = os.getenv(\"HOME\")+'/aiffel/class_activation_map/cam_model.h5'\n",
    "cam_model.save(cam_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
